{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdda0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import sklearn.metrics as metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'Path to Dataset'\n",
    "counter = 0\n",
    "img_path = []\n",
    "for root, dirs, files in os.walk(img_dir):\n",
    "    for filename in files:\n",
    "        path = root + '/' + filename\n",
    "        if 'nii.gz' in path:\n",
    "            counter += 1\n",
    "            img_path.append(path)\n",
    "\n",
    "def fetchImg(element):\n",
    "    for path in img_path:\n",
    "        if str(element) in path:\n",
    "            img_name = path\n",
    "            elem = img_name.split('_')[-1][:4]\n",
    "            image_data = nib.load(img_name).get_fdata()[:, :, :]\n",
    "    return image_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('Path to labels csv file', header=0)\n",
    "\n",
    "t_labels = labels.iloc[labels.index % 3 != 2]\n",
    "v_labels = labels.iloc[labels.index % 3 == 2]\n",
    "\n",
    "# sort training set \n",
    "normal_df = t_labels.loc[t_labels['Diagnosis Category'] == 'Normal']\n",
    "deformity_df = t_labels.loc[t_labels['Diagnosis Category'] == 'Deformity']\n",
    "fracture_df = t_labels.loc[t_labels['Diagnosis Category'] == 'Osteoporotic Fracture']\n",
    "\n",
    "sorted_imgs = [normal_df, deformity_df, fracture_df]\n",
    "\n",
    "# sort validation set\n",
    "v_normal = v_labels.loc[v_labels['Diagnosis Category'] == 'Normal']\n",
    "v_deformity = v_labels.loc[v_labels['Diagnosis Category'] == 'Deformity']\n",
    "v_fracture = v_labels.loc[v_labels['Diagnosis Category'] == 'Osteoporotic Fracture']\n",
    "\n",
    "sorted_imgs_val = [v_normal, v_deformity, v_fracture]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "def affine_augmentation(image, center): #adjust centre-coordinate after augmentation\n",
    "    try:\n",
    "        B,C,D,H,W = image.shape\n",
    "    except:\n",
    "        D,H,W = image.shape\n",
    "        B = 1\n",
    "        C = 1\n",
    "        image = image.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "    #print(image.shape)\n",
    "    center_grid = torch.zeros((B,C,D,H,W))\n",
    "    if center[0] > D:\n",
    "        print('centerD', center)\n",
    "    if center[1] > H:\n",
    "        print('centerH', center)\n",
    "    if center[2] > W:\n",
    "        print('centerW', center)\n",
    "    center_grid[0,0,int(center[0]), int(center[1]), int(center[2])] = 1\n",
    "    with torch.no_grad():\n",
    "        affine = F.affine_grid(torch.eye(3, 4).unsqueeze(0) + torch.randn(B, 3, 4) * .07, (B, C, D, H, W)).cuda()\n",
    "        img = F.grid_sample(image.cuda().float(), affine, padding_mode='zeros', mode='trilinear').squeeze(0)\n",
    "        center_transformed = F.grid_sample(center_grid.cuda(), affine, padding_mode='border', mode='nearest').squeeze(0).squeeze(0)\n",
    "        new_center = center_transformed.nonzero()\n",
    "    return img, new_center.cpu()\n",
    "\n",
    "\n",
    "def crop_center(image, center, output_size): #crop using the centre coordinate label\n",
    "    cropped = np.zeros(output_size)\n",
    "    upper = center + (output_size/2)\n",
    "    lower = center - (output_size/2)\n",
    "    for i in range(3):\n",
    "        if upper[i] > image.shape[i]:\n",
    "            upper[i] = image.shape[i]\n",
    "        if lower[i] < 0:\n",
    "            lower[i] = 0\n",
    "            \n",
    "    z1 = int(lower[0])\n",
    "    z2 = int(upper[0])\n",
    "    y1 = int(lower[1])\n",
    "    y2 = int(upper[1])\n",
    "    x1 = int(lower[2])\n",
    "    x2 = int(upper[2])\n",
    "    \n",
    "    cz = 0; cy = 0; cx = 0;\n",
    "\n",
    "    if z2 - z1 < output_size[0]:#np.abs(z2-z1)\n",
    "        cz = output_size[0] - np.abs(z2 - z1)\n",
    "    if y2 - y1 < output_size[1]:\n",
    "        cy = output_size[1] - np.abs(y2 - y1)\n",
    "    if x2 - x1 < output_size[2]:\n",
    "        cx = output_size[2] - np.abs(x2 - x1)\n",
    "\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3726521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model \n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv3d(1, 64, kernel_size=5),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 64, kernel_size=5),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool1 = nn.MaxPool3d(3)\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 128, kernel_size=3),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(128, 128, kernel_size=3),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool2 = nn.MaxPool3d(3)\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv3d(128, 256, kernel_size=3, stride=1, padding = 1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool3 = nn.MaxPool3d(3)\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.Conv3d(256, 512, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.pool4 = nn.MaxPool3d((1,3,3))\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv3d(512, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(64, 3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        out1 = checkpoint(self.block1, inputs)\n",
    "        outpool1 = self.pool1(out1)\n",
    "        out2 = checkpoint(self.block2, outpool1)\n",
    "        outpool2 = self.pool2(out2)\n",
    "        out3 = checkpoint(self.block3, outpool2)\n",
    "        outpool3 = self.pool3(out3)\n",
    "        out4 = checkpoint(self.block4, outpool3)\n",
    "        outpool4 = self.pool4(out4)\n",
    "        out = checkpoint(self.out, outpool4)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training config\n",
    "model = ClassificationModel()\n",
    "\n",
    "model.cuda()\n",
    "model.train()\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.0001)\n",
    "\n",
    "epochs = 4500\n",
    "run_loss = torch.zeros(epochs)\n",
    "val_loss = torch.zeros(epochs)\n",
    "B = 12\n",
    "D, H, W = (64, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d301e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "ts = time.time()\n",
    "for i in range(epochs):\n",
    "    t0 = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    #draw random minibatch from sorted_imgs list\n",
    "    c = torch.randint(0,3,(B,))\n",
    "    target = c.long().cuda()\n",
    "    img = torch.zeros(B,1,D,H,W)\n",
    "    ii = 0\n",
    "    for idx in c:\n",
    "        #fetch image, augmentation, cropping\n",
    "        ind = torch.randint(0,len(sorted_imgs[idx].index),(1,))\n",
    "        content = labels.iloc[sorted_imgs[idx].index[ind]]\n",
    "        patientID = content['Patient']\n",
    "        center = np.asarray([content['CenterZ'], content['CenterY'], content['CenterX']])\n",
    "        image = fetchImg(patientID)\n",
    "        aug_img, new_center = affine_augmentation(torch.from_numpy(image), center)\n",
    "        new_center = np.asarray([int(center[0]), int(center[1]), int(center[2])])\n",
    "        cropped = crop_center(aug_img.cpu().numpy().squeeze(0), new_center[0], np.asarray([D, H, W]))\n",
    "        img_tmp = torch.from_numpy(cropped).unsqueeze(0).unsqueeze(0)\n",
    "        img[ii] = img_tmp.cuda()\n",
    "        ii +=1\n",
    "    \n",
    "    img.requires_grad = True   \n",
    "\n",
    "    model.train()\n",
    "    with torch.cuda.amp.autocast():\n",
    "    \n",
    "        with torch.set_grad_enabled(True ):\n",
    "            out = model(img.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            predict = torch.log_softmax(out, 1)\n",
    "            loss = nn.NLLLoss()(predict, target.long().cuda())  \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            run_loss[i] = loss.item()\n",
    "            optimizer.step()\n",
    "            if (i % 100 == 99):\n",
    "                print(i, time.time() - t0, 'sec', 'loss_train', run_loss[i-10:i].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
